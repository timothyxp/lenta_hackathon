{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, matplotlib as mpl, matplotlib.pyplot as plt, pandas as pd\n",
    "import seaborn as sns, math, os, warnings\n",
    "from azureml.core import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подключаемся к workspace и скачиваем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are currently using version 1.8.0 of the Azure ML SDK\n",
      "\n",
      "Workspace name: team25\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.core import Experiment, Workspace\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"You are currently using version\", azureml.core.VERSION, \"of the Azure ML SDK\")\n",
    "print(\"\")\n",
    "\n",
    "# Log In to Azure ML Workspace\n",
    "interactive_auth = InteractiveLoginAuthentication(tenant_id=\"76f90eb1-fb9a-4446-9875-4d323d6455ad\")\n",
    "\n",
    "ws = Workspace.from_config(auth=interactive_auth)\n",
    "print('Workspace name: ' + ws.name, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py37_default/lib/python3.7/site-packages/azureml/dataprep/api/dataflow.py:722: UserWarning: Your pandas and pyarrow versions are incompatible. Please install pyarrow>=0.12.0 for improved performance of to_pandas_dataframe. You can ensure the correct version is installed by running: pip install pyarrow>=0.12.0 --upgrade\n",
      "  warnings.warn('Your pandas and pyarrow versions are incompatible. '\n"
     ]
    }
   ],
   "source": [
    "aml_dataset = Dataset.get_by_name(ws, 'train_ds', version='latest')\n",
    "pdf = aml_dataset.to_pandas_dataframe()\n",
    "df_data = pdf.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготавливаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_data.rename(columns={'response_att': 'target'})\n",
    "# Rename & Label encode treatment column\n",
    "df_data = df_data.rename(columns={'group': 'treatment'})\n",
    "df_data.treatment = df_data.treatment.map({'control': 0, 'test': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def declare_tc(df:pd.DataFrame):\n",
    "    \"\"\"Declare target class\n",
    "    \"\"\"\n",
    "    #CN:\n",
    "    df['target_class'] = 0 \n",
    "    #CR:\n",
    "    df.loc[(df.treatment == 0) & (df.target != 0),'target_class'] = 1 \n",
    "    #TN:\n",
    "    df.loc[(df.treatment != 0) & (df.target == 0),'target_class'] = 2 \n",
    "    #TR:\n",
    "    df.loc[(df.treatment != 0) & (df.target != 0),'target_class'] = 3 \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.gender = [0 if x == 'Ж' else 1 for x in df_data.gender]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = declare_tc(df_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функции для разбиения и тестирования train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "def uplift_split(df_data:pd.DataFrame):\n",
    "    \"\"\"Train-Test Split\n",
    "    \"\"\"\n",
    "    X = df_data.drop(['target','target_class'], axis=1)\n",
    "    y = df_data.target_class\n",
    "    X_train, X_test, \\\n",
    "    y_train, y_test  = train_test_split(df_data.drop(['target_class'],axis=1),\n",
    "                                       y,\n",
    "                                       test_size=0.2,\n",
    "                                       random_state=42)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uplift_model(X_train:pd.DataFrame,\n",
    "                 X_test:pd.DataFrame,\n",
    "                 y_train:pd.DataFrame,\n",
    "                 y_test:pd.DataFrame,\n",
    "                lqb_params):\n",
    "    \"\"\"Using XGB to get the uplift score\n",
    "    \"\"\"\n",
    "    # Create new dataframe\n",
    "    result = pd.DataFrame(X_test).copy()    \n",
    "    # Fit the model\n",
    "    uplift_model \\\n",
    "    = lgb.LGBMClassifier(**lqb_params).fit(\n",
    "        X_train.drop(['treatment', 'target'],axis=1), y_train,\n",
    "        eval_set=[(X_test.drop(['treatment', 'target'],axis=1), y_test)],\n",
    "        verbose=50,\n",
    "        early_stopping_rounds=50,\n",
    "        eval_metric=\"logloss\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Predict using test-data\n",
    "    uplift_proba \\\n",
    "    = uplift_model.predict_proba(X_test.drop(['treatment', 'target'], axis=1))\n",
    "    result['proba_CN'] = uplift_proba[:,0] \n",
    "    result['proba_CR'] = uplift_proba[:,1] \n",
    "    result['proba_TN'] = uplift_proba[:,2] \n",
    "    result['proba_TR'] = uplift_proba[:,3]\n",
    "    result['uplift'] = result.eval('\\\n",
    "    proba_CN/(proba_CN+proba_CR) \\\n",
    "    + proba_TR/(proba_TN+proba_TR) \\\n",
    "    - proba_TN/(proba_TN+proba_TR) \\\n",
    "    - proba_CR/(proba_CN+proba_CR)')  \n",
    "    # Put the result \n",
    "    result['target_class'] = y_test\n",
    "    result['target'] = X_test['target']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uplift(df_data:pd.DataFrame, lqb_params):\n",
    "    \"\"\"Combine the split and Modeling function\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = uplift_split(df_data)\n",
    "    result = uplift_model(X_train, X_test, y_train, y_test, lqb_params)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = uplift(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "lgbm_hp_hyper_space = {\n",
    "    \"boosting_type\": hp.choice(\"boosting_type\", [\"gbdt\", \"dart\"]),\n",
    "    \"objective\": hp.choice(\"objective\", \"binary\"),\n",
    "    \"n_estimators\": 600,\n",
    "    \"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.1),\n",
    "    'subsample': hp.uniform('subsample', 0.2, 0.7),\n",
    "    'feature_fraction': hp.uniform('feature_fraction', 0.2, 0.7),\n",
    "    \"num_leaves\": 4 + hp.randint(\"num_leaves\", 28),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", [2, 3, 4, 5]),\n",
    "    \"n_jobs\": 30\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, Trials, space_eval\n",
    "from functools import partial\n",
    "\n",
    "trials = Trials()\n",
    "algo = partial(\n",
    "    tpe.suggest,\n",
    "    n_startup_jobs=10,\n",
    "    gamma=0.25,\n",
    "    n_EI_candidates=24\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boosting_type': 'dart', 'feature_fraction': 0.5820290153544719, 'learning_rate': 0.010416083794593927, 'max_depth': 4, 'n_estimators': 600, 'n_jobs': 30, 'num_leaves': 18, 'objective': 'b', 'subsample': 0.6959176517648378}\n",
      "[50]\tvalid_0's multi_logloss: 0.885496                         \n",
      "[100]\tvalid_0's multi_logloss: 0.938396                       \n",
      "[150]\tvalid_0's multi_logloss: 0.97406                        \n",
      "[200]\tvalid_0's multi_logloss: 0.97516                        \n",
      "[250]\tvalid_0's multi_logloss: 0.966778                       \n",
      "[300]\tvalid_0's multi_logloss: 0.946903                       \n",
      "[350]\tvalid_0's multi_logloss: 0.941444                       \n",
      "[400]\tvalid_0's multi_logloss: 0.920278                       \n",
      "[450]\tvalid_0's multi_logloss: 0.907478                       \n",
      "[500]\tvalid_0's multi_logloss: 0.898386                       \n",
      "[550]\tvalid_0's multi_logloss: 0.890855                       \n",
      "[600]\tvalid_0's multi_logloss: 0.890633                       \n",
      "score = 5.9447680731114145                                    \n",
      "{'boosting_type': 'dart', 'feature_fraction': 0.38122485784799287, 'learning_rate': 0.08439146842918391, 'max_depth': 3, 'n_estimators': 600, 'n_jobs': 30, 'num_leaves': 24, 'objective': 'y', 'subsample': 0.32703436474904024}\n",
      "[50]\tvalid_0's multi_logloss: 0.845306                                               \n",
      "[100]\tvalid_0's multi_logloss: 0.849539                                              \n",
      "[150]\tvalid_0's multi_logloss: 0.84603                                               \n",
      "[200]\tvalid_0's multi_logloss: 0.837297                                              \n",
      "[250]\tvalid_0's multi_logloss: 0.833825                                              \n",
      "[300]\tvalid_0's multi_logloss: 0.831275                                              \n",
      "[350]\tvalid_0's multi_logloss: 0.830447                                              \n",
      "[400]\tvalid_0's multi_logloss: 0.828602                                              \n",
      "[450]\tvalid_0's multi_logloss: 0.827697                                              \n",
      "[500]\tvalid_0's multi_logloss: 0.827308                                              \n",
      "[550]\tvalid_0's multi_logloss: 0.827156                                              \n",
      "[600]\tvalid_0's multi_logloss: 0.827332                                              \n",
      "score = 3.500161934420581                                                            \n",
      "{'boosting_type': 'dart', 'feature_fraction': 0.6794490898234802, 'learning_rate': 0.07765085595838903, 'max_depth': 4, 'n_estimators': 600, 'n_jobs': 30, 'num_leaves': 18, 'objective': 'y', 'subsample': 0.472108399103791}\n",
      "[50]\tvalid_0's multi_logloss: 0.840759                                               \n",
      "[100]\tvalid_0's multi_logloss: 0.84691                                               \n",
      "[150]\tvalid_0's multi_logloss: 0.844062                                              \n",
      "[200]\tvalid_0's multi_logloss: 0.83479                                               \n",
      "[250]\tvalid_0's multi_logloss: 0.830721                                              \n",
      "[300]\tvalid_0's multi_logloss: 0.82832                                               \n",
      "[350]\tvalid_0's multi_logloss: 0.827747                                              \n",
      "[400]\tvalid_0's multi_logloss: 0.825975                                              \n",
      "[450]\tvalid_0's multi_logloss: 0.825391                                              \n",
      "[500]\tvalid_0's multi_logloss: 0.825097                                              \n",
      "[550]\tvalid_0's multi_logloss: 0.825013                                              \n",
      "[600]\tvalid_0's multi_logloss: 0.825364                                              \n",
      "score = 3.526882981363083                                                            \n",
      "{'boosting_type': 'dart', 'feature_fraction': 0.5086543543074735, 'learning_rate': 0.01335695051743725, 'max_depth': 5, 'n_estimators': 600, 'n_jobs': 30, 'num_leaves': 19, 'objective': 'y', 'subsample': 0.20268142020499896}\n",
      "[50]\tvalid_0's multi_logloss: 0.880986                                               \n",
      "[100]\tvalid_0's multi_logloss: 0.929244                                              \n",
      "[150]\tvalid_0's multi_logloss: 0.958534                                              \n",
      "[200]\tvalid_0's multi_logloss: 0.953866                                              \n",
      "[250]\tvalid_0's multi_logloss: 0.942372                                              \n",
      "[300]\tvalid_0's multi_logloss: 0.922143                                              \n",
      "[350]\tvalid_0's multi_logloss: 0.915975                                              \n",
      "[400]\tvalid_0's multi_logloss: 0.895863                                              \n",
      "[450]\tvalid_0's multi_logloss: 0.884047                                              \n",
      "[500]\tvalid_0's multi_logloss: 0.876323                                              \n",
      "[550]\tvalid_0's multi_logloss: 0.87013                                               \n",
      "[600]\tvalid_0's multi_logloss: 0.870285                                              \n",
      "score = 5.853923681088402                                                            \n",
      "{'boosting_type': 'dart', 'feature_fraction': 0.3774436652921725, 'learning_rate': 0.03874500078406294, 'max_depth': 3, 'n_estimators': 600, 'n_jobs': 30, 'num_leaves': 9, 'objective': 'a', 'subsample': 0.36594102947123686}\n",
      "[50]\tvalid_0's multi_logloss: 0.86136                                                \n",
      "[100]\tvalid_0's multi_logloss: 0.883574                                              \n",
      "[150]\tvalid_0's multi_logloss: 0.886432                                              \n",
      "[200]\tvalid_0's multi_logloss: 0.870293                                              \n",
      "[250]\tvalid_0's multi_logloss: 0.859513                                              \n",
      "[300]\tvalid_0's multi_logloss: 0.849443                                              \n",
      "[350]\tvalid_0's multi_logloss: 0.846287                                              \n",
      "[400]\tvalid_0's multi_logloss: 0.839048                                              \n",
      "[450]\tvalid_0's multi_logloss: 0.835777                                              \n",
      "[500]\tvalid_0's multi_logloss: 0.834231                                              \n",
      "[550]\tvalid_0's multi_logloss: 0.833413                                              \n",
      "[600]\tvalid_0's multi_logloss: 0.833951                                              \n",
      "score = 3.8458355796108625                                                           \n",
      "{'boosting_type': 'dart', 'feature_fraction': 0.6065134743779999, 'learning_rate': 0.06842654992206174, 'max_depth': 4, 'n_estimators': 600, 'n_jobs': 30, 'num_leaves': 25, 'objective': 'b', 'subsample': 0.5198295560977306}\n",
      "[50]\tvalid_0's multi_logloss: 0.843641                                               \n",
      "[100]\tvalid_0's multi_logloss: 0.852011                                              \n",
      "[150]\tvalid_0's multi_logloss: 0.849414                                              \n",
      "[200]\tvalid_0's multi_logloss: 0.838444                                              \n",
      "[250]\tvalid_0's multi_logloss: 0.833227                                              \n",
      "[300]\tvalid_0's multi_logloss: 0.829776                                              \n",
      "[350]\tvalid_0's multi_logloss: 0.829056                                              \n",
      "[400]\tvalid_0's multi_logloss: 0.826729                                              \n",
      "[450]\tvalid_0's multi_logloss: 0.825973                                              \n",
      "[500]\tvalid_0's multi_logloss: 0.825624                                              \n",
      "[550]\tvalid_0's multi_logloss: 0.82548                                               \n",
      "[600]\tvalid_0's multi_logloss: 0.825957                                              \n",
      "score = 3.436475464035413                                                            \n",
      "{'boosting_type': 'dart', 'feature_fraction': 0.4036055978334005, 'learning_rate': 0.03659112324795971, 'max_depth': 4, 'n_estimators': 600, 'n_jobs': 30, 'num_leaves': 12, 'objective': 'r', 'subsample': 0.6891273199836816}\n",
      "[50]\tvalid_0's multi_logloss: 0.860943                                               \n",
      "[100]\tvalid_0's multi_logloss: 0.884595                                              \n",
      "[150]\tvalid_0's multi_logloss: 0.888425                                              \n",
      "[200]\tvalid_0's multi_logloss: 0.872203                                              \n",
      "[250]\tvalid_0's multi_logloss: 0.860543                                              \n",
      "[300]\tvalid_0's multi_logloss: 0.849731                                              \n",
      "[350]\tvalid_0's multi_logloss: 0.84634                                               \n",
      "[400]\tvalid_0's multi_logloss: 0.83848                                               \n",
      "[450]\tvalid_0's multi_logloss: 0.834893                                              \n",
      "[500]\tvalid_0's multi_logloss: 0.833156                                              \n",
      "[550]\tvalid_0's multi_logloss: 0.832297                                              \n",
      " 30%|███       | 15/50 [16:23<1:25:35, 146.74s/trial, best loss: -6.0160317115326905]"
     ]
    }
   ],
   "source": [
    "def optimization_function(params):\n",
    "    print(params)\n",
    "    res = uplift(df_data, params)\n",
    "    score = custom_metric(res)\n",
    "    print(f\"score = {score}\")\n",
    "    \n",
    "    return -score\n",
    "    \n",
    "\n",
    "best = fmin(\n",
    "    optimization_function,\n",
    "    space=lgbm_hp_hyper_space,\n",
    "    algo=algo,\n",
    "    max_evals=50,\n",
    "    trials=trials,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_metric(answers, take_top_ratio=0.25):\n",
    "    answers.sort_values(by='uplift', inplace=True, ascending=False)\n",
    "    n_samples = int(np.ceil(answers.shape[0] * take_top_ratio))\n",
    "    answers = answers.iloc[:n_samples, :]\n",
    "    answers_test = answers[answers['treatment'] == 1]['target'].sum() / \\\n",
    "                   answers[answers['treatment'] == 1].shape[0]\n",
    "    answers_control = answers[answers['treatment'] == 0]['target'].sum() / \\\n",
    "                      answers[answers['treatment'] == 0].shape[0]\n",
    "    return (answers_test - answers_control) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_data.drop(['target_class'], axis=1)\n",
    "y = df_data.target_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "uplift_model \\\n",
    "    = lgb.LGBMClassifier().fit(X.drop(['treatment', 'target'],axis=1), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка тест выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py37_default/lib/python3.7/site-packages/azureml/dataprep/api/dataflow.py:722: UserWarning: Your pandas and pyarrow versions are incompatible. Please install pyarrow>=0.12.0 for improved performance of to_pandas_dataframe. You can ensure the correct version is installed by running: pip install pyarrow>=0.12.0 --upgrade\n",
      "  warnings.warn('Your pandas and pyarrow versions are incompatible. '\n"
     ]
    }
   ],
   "source": [
    "aml_dataset = Dataset.get_by_name(ws, 'test_ds', version='latest')\n",
    "df_test = aml_dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.gender = [0 if x == 'Ж' else 1 for x in df_test.gender]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(df_test).copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "uplift_proba \\\n",
    "    = uplift_model.predict_proba(df_test)\n",
    "result['proba_CN'] = uplift_proba[:,0] \n",
    "result['proba_CR'] = uplift_proba[:,1] \n",
    "result['proba_TN'] = uplift_proba[:,2] \n",
    "result['proba_TR'] = uplift_proba[:,3]\n",
    "result['uplift'] = result.eval('\\\n",
    "proba_CN/(proba_CN+proba_CR) \\\n",
    "+ proba_TR/(proba_TN+proba_TR) \\\n",
    "- proba_TN/(proba_TN+proba_TR) \\\n",
    "- proba_CR/(proba_CN+proba_CR)')  \n",
    "# Put the result \n",
    "#result['target_class'] = y_test\n",
    "#result['target'] = X_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CardHolder</th>\n",
       "      <th>age</th>\n",
       "      <th>cheque_count_12m_g20</th>\n",
       "      <th>cheque_count_12m_g21</th>\n",
       "      <th>cheque_count_12m_g25</th>\n",
       "      <th>cheque_count_12m_g32</th>\n",
       "      <th>cheque_count_12m_g33</th>\n",
       "      <th>cheque_count_12m_g38</th>\n",
       "      <th>cheque_count_12m_g39</th>\n",
       "      <th>cheque_count_12m_g41</th>\n",
       "      <th>...</th>\n",
       "      <th>sale_sum_6m_g44</th>\n",
       "      <th>sale_sum_6m_g54</th>\n",
       "      <th>stdev_days_between_visits_15d</th>\n",
       "      <th>stdev_discount_depth_15d</th>\n",
       "      <th>stdev_discount_depth_1m</th>\n",
       "      <th>proba_CN</th>\n",
       "      <th>proba_CR</th>\n",
       "      <th>proba_TN</th>\n",
       "      <th>proba_TR</th>\n",
       "      <th>uplift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16400802</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>192.76</td>\n",
       "      <td>32.17</td>\n",
       "      <td>2.8868</td>\n",
       "      <td>0.3266</td>\n",
       "      <td>0.3699</td>\n",
       "      <td>0.186164</td>\n",
       "      <td>0.055891</td>\n",
       "      <td>0.553912</td>\n",
       "      <td>0.204033</td>\n",
       "      <td>0.076579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15752880</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.216491</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>0.768937</td>\n",
       "      <td>0.010802</td>\n",
       "      <td>-0.006513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15978290</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41.99</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.227581</td>\n",
       "      <td>0.007870</td>\n",
       "      <td>0.735668</td>\n",
       "      <td>0.028882</td>\n",
       "      <td>0.008702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16604118</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>388.23</td>\n",
       "      <td>721.33</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.217346</td>\n",
       "      <td>0.018284</td>\n",
       "      <td>0.696829</td>\n",
       "      <td>0.067540</td>\n",
       "      <td>0.021526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15880709</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>336.49</td>\n",
       "      <td>306.66</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3627</td>\n",
       "      <td>0.2688</td>\n",
       "      <td>0.211381</td>\n",
       "      <td>0.021493</td>\n",
       "      <td>0.694263</td>\n",
       "      <td>0.072863</td>\n",
       "      <td>0.005376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CardHolder   age  cheque_count_12m_g20  cheque_count_12m_g21  \\\n",
       "0    16400802  26.0                   0.0                   0.0   \n",
       "1    15752880  73.0                   0.0                   0.0   \n",
       "2    15978290  32.0                   0.0                   0.0   \n",
       "3    16604118  24.0                   0.0                   0.0   \n",
       "4    15880709  42.0                   0.0                   0.0   \n",
       "\n",
       "   cheque_count_12m_g25  cheque_count_12m_g32  cheque_count_12m_g33  \\\n",
       "0                   4.0                   0.0                   0.0   \n",
       "1                   0.0                   0.0                   0.0   \n",
       "2                   2.0                   0.0                   0.0   \n",
       "3                   0.0                   0.0                   0.0   \n",
       "4                   1.0                   1.0                   3.0   \n",
       "\n",
       "   cheque_count_12m_g38  cheque_count_12m_g39  cheque_count_12m_g41  ...  \\\n",
       "0                   0.0                   0.0                   5.0  ...   \n",
       "1                   0.0                   0.0                   1.0  ...   \n",
       "2                   0.0                   0.0                   3.0  ...   \n",
       "3                   3.0                   1.0                   2.0  ...   \n",
       "4                   1.0                   2.0                   0.0  ...   \n",
       "\n",
       "   sale_sum_6m_g44  sale_sum_6m_g54  stdev_days_between_visits_15d  \\\n",
       "0           192.76            32.17                         2.8868   \n",
       "1              NaN              NaN                         0.0000   \n",
       "2             0.00            41.99                         0.0000   \n",
       "3           388.23           721.33                         0.0000   \n",
       "4           336.49           306.66                         0.0000   \n",
       "\n",
       "   stdev_discount_depth_15d  stdev_discount_depth_1m  proba_CN  proba_CR  \\\n",
       "0                    0.3266                   0.3699  0.186164  0.055891   \n",
       "1                    0.0000                   0.0000  0.216491  0.003769   \n",
       "2                    0.0000                   0.0000  0.227581  0.007870   \n",
       "3                       NaN                      NaN  0.217346  0.018284   \n",
       "4                    0.3627                   0.2688  0.211381  0.021493   \n",
       "\n",
       "   proba_TN  proba_TR    uplift  \n",
       "0  0.553912  0.204033  0.076579  \n",
       "1  0.768937  0.010802 -0.006513  \n",
       "2  0.735668  0.028882  0.008702  \n",
       "3  0.696829  0.067540  0.021526  \n",
       "4  0.694263  0.072863  0.005376  \n",
       "\n",
       "[5 rows x 199 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = df_test[['CardHolder']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py37_default/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "submission['uplift'] = result['uplift']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CardHolder</th>\n",
       "      <th>uplift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16400802</td>\n",
       "      <td>0.076579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15752880</td>\n",
       "      <td>-0.006513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15978290</td>\n",
       "      <td>0.008702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16604118</td>\n",
       "      <td>0.021526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15880709</td>\n",
       "      <td>0.005376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CardHolder    uplift\n",
       "0    16400802  0.076579\n",
       "1    15752880 -0.006513\n",
       "2    15978290  0.008702\n",
       "3    16604118  0.021526\n",
       "4    15880709  0.005376"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('4submission.csv', index=False, sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
